{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94193b06-883a-456c-a958-f9e91ce77f66",
   "metadata": {},
   "source": [
    "# Billboard - Genre"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6a1c41-6be2-44f8-8c96-e6e1a058f49d",
   "metadata": {},
   "source": [
    "## Yearly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9d0bb6-6ac0-49fa-a9c5-155d7ab78234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the unique genre list from the CSV file using raw string\n",
    "genre_df = pd.read_csv(r'[EN] Unique Genre Counts.csv')\n",
    "\n",
    "# Assuming the genre list is in a column named 'Genre'\n",
    "unique_genres = genre_df['Genre'].tolist()\n",
    "genre_list_str = ', '.join(unique_genres)\n",
    "print(genre_list_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98190f6a-d68e-40d8-9246-cf20c43b00b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import requests\n",
    "from openai import OpenAI\n",
    "\n",
    "# Function to prepare the zero-shot payload\n",
    "def prepare_zero_shot_payload(lyrics, unique_genres):\n",
    "    genre_list_str = ', '.join(unique_genres)\n",
    "    \n",
    "    prompt = (\n",
    "        f\"Here is a list of unique music genres: [{genre_list_str}].\\n\\n\"\n",
    "        f\"Say nothing but the Genre as Genre: {{the output}}\\n\\n\"\n",
    "        f\"Output example: Genre: [pop, r&b, hip hop]\\n\\n\"\n",
    "        f\"Lyrics: '{lyrics}'\\n\\n\"\n",
    "        f\"Genres: \"\n",
    "    )\n",
    "    \n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    \n",
    "    payload = {\n",
    "        \"model\": \"gpt-4o\",\n",
    "        \"messages\": messages,\n",
    "        \"max_tokens\": 40,\n",
    "        \"temperature\": 0\n",
    "    }\n",
    "    \n",
    "    return payload\n",
    "\n",
    "# Function to prepare the chain-of-thought prompt payload\n",
    "def prepare_cot_payload(lyrics, unique_genres):\n",
    "    genre_list_str = ', '.join(unique_genres)\n",
    "    \n",
    "    prompt = (\n",
    "        f\"Here is a list of unique music genres: [{genre_list_str}].\\n\\n\"\n",
    "        f\"Based on the lyrics provided, identify the genres.\\n\\n\"\n",
    "        f\"Say nothing but the Genre as Genre: {{the output}}\\n\\n\"\n",
    "        f\"Output example: Genre: [pop, r&b, hip hop]\\n\\n\"\n",
    "        f\"Lyrics: '{lyrics}'\\n\\n\"\n",
    "        f\"Genre:\"\n",
    "    )\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    \n",
    "    payload = {\n",
    "        \"model\": \"gpt-4o\",\n",
    "        \"messages\": messages,\n",
    "        \"max_tokens\": 40,\n",
    "        \"temperature\": 0\n",
    "    }\n",
    "    \n",
    "    return payload\n",
    "\n",
    "# Function to prepare the chain-of-thought few-shot prompt payload\n",
    "def prepare_cot_few_shot_payload(lyrics, unique_genres):\n",
    "    genre_list_str = ', '.join(unique_genres)\n",
    "    \n",
    "    example_lyrics = (\n",
    "        \"And she spoke words that would melt in your hands\\n\"\n",
    "        \"And she spoke words of wisdom\\n\"\n",
    "        \"To the basement, people, to the basement\\n\"\n",
    "        \"Many surprises await you\\n\"\n",
    "        \"In the basement, people, in the basement\\n\"\n",
    "        \"\\n\"\n",
    "        \"You hid there last time, you know we're gonna find you\\n\"\n",
    "        \"Sick in the car seat, 'cause you're not up to going\\n\"\n",
    "        \"Out on the main streets, completing your mission\\n\"\n",
    "        \"You hid there last time, you know we're gonna find you\\n\"\n",
    "        \"Sick in the car seat, 'cause you're not up to going\\n\"\n",
    "        \"Out on the main streets, completing your mission\\n\"\n",
    "    )\n",
    "\n",
    "    example_genres = \"indie pop\"\n",
    "\n",
    "    prompt = (\n",
    "        f\"Here is a list of unique music genres: [{genre_list_str}].\\n\\n\"\n",
    "        \n",
    "        f\"Example:\\n\\n\"\n",
    "        f\"Lyrics: '{example_lyrics}'\\n\\n\"\n",
    "        f\"Genre: {example_genres}\\n\\n\"\n",
    "\n",
    "        f\"Now, based on the provided lyrics, identify the genres.\\n\\n\"\n",
    "        f\"Say nothing but the Genre as Genre: {{the output}}\\n\\n\"\n",
    "        f\"Output example: Genre: [pop, r&b, hip hop]\\n\\n\"\n",
    "        f\"Lyrics: '{lyrics}'\\n\\n\"\n",
    "        f\"Genre:\"\n",
    "    )\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    \n",
    "    payload = {\n",
    "        \"model\": \"gpt-4o\",\n",
    "        \"messages\": messages,\n",
    "        \"max_tokens\": 40,\n",
    "        \"temperature\": 0\n",
    "    }\n",
    "    \n",
    "    return payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396e92ce-5f3e-46b6-83e5-6078f63735fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = #“Enter your own API code”\n",
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8849e75-272c-493a-b7ac-6cbfee6e9ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Billboard_yearly_filtered.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4de658d-5312-4f59-8468-98778b84ced3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the tasks for each method\n",
    "tasks_zero_shot = []\n",
    "tasks_cot = []\n",
    "tasks_cot_few_shot = []\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    lyrics = row['lyrics']\n",
    "    \n",
    "    # Zero-shot task\n",
    "    payload_zero_shot = prepare_zero_shot_payload(lyrics, unique_genres)\n",
    "    task_zero_shot = {\n",
    "        \"custom_id\": f\"zero_shot_{i}\",\n",
    "        \"method\": \"POST\",\n",
    "        \"url\": \"/v1/chat/completions\",\n",
    "        \"body\": payload_zero_shot\n",
    "    }\n",
    "    tasks_zero_shot.append(task_zero_shot)\n",
    "    \n",
    "    # Chain-of-thought task\n",
    "    payload_cot = prepare_cot_payload(lyrics, unique_genres)\n",
    "    task_cot = {\n",
    "        \"custom_id\": f\"cot_{i}\",\n",
    "        \"method\": \"POST\",\n",
    "        \"url\": \"/v1/chat/completions\",\n",
    "        \"body\": payload_cot\n",
    "    }\n",
    "    tasks_cot.append(task_cot)\n",
    "    \n",
    "    # Chain-of-thought few-shot task\n",
    "    payload_cot_few_shot = prepare_cot_few_shot_payload(lyrics, unique_genres)\n",
    "    task_cot_few_shot = {\n",
    "        \"custom_id\": f\"cot_few_shot_{i}\",\n",
    "        \"method\": \"POST\",\n",
    "        \"url\": \"/v1/chat/completions\",\n",
    "        \"body\": payload_cot_few_shot\n",
    "    }\n",
    "    tasks_cot_few_shot.append(task_cot_few_shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe74383-0508-4186-8799-d3bdbbb7a64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save tasks to JSONL files\n",
    "file_name_zero_shot = \"batch_zero_shot.jsonl\"\n",
    "file_name_cot = \"batch_cot.jsonl\"\n",
    "file_name_cot_few_shot = \"batch_cot_few_shot.jsonl\"\n",
    "\n",
    "def save_tasks_to_file(file_name, tasks):\n",
    "    with open(file_name, 'w') as file:\n",
    "        for task in tasks:\n",
    "            file.write(json.dumps(task) + '\\n')\n",
    "\n",
    "save_tasks_to_file(file_name_zero_shot, tasks_zero_shot)\n",
    "save_tasks_to_file(file_name_cot, tasks_cot)\n",
    "save_tasks_to_file(file_name_cot_few_shot, tasks_cot_few_shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d422a76a-0a78-40f6-9fe9-e8f2e05eaa74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the files\n",
    "batch_file_zero_shot = client.files.create(file=open(file_name_zero_shot, \"rb\"), purpose=\"batch\")\n",
    "batch_file_cot = client.files.create(file=open(file_name_cot, \"rb\"), purpose=\"batch\")\n",
    "batch_file_cot_few_shot = client.files.create(file=open(file_name_cot_few_shot, \"rb\"), purpose=\"batch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde10eb3-286d-44f9-bbee-66298dc97dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the batch jobs\n",
    "batch_job_zero_shot = client.batches.create(\n",
    "    input_file_id=batch_file_zero_shot.id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\"\n",
    ")\n",
    "\n",
    "batch_job_cot = client.batches.create(\n",
    "    input_file_id=batch_file_cot.id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\"\n",
    ")\n",
    "\n",
    "batch_job_cot_few_shot = client.batches.create(\n",
    "    input_file_id=batch_file_cot_few_shot.id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3857dc-4167-406a-8dbc-39739facf0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch job IDs from the status output\n",
    "batch_job_zero_shot_id = #file id\n",
    "batch_job_cot_id = #file id\n",
    "batch_job_cot_few_shot_id = #file id\n",
    "\n",
    "# Checking the status of the batch jobs\n",
    "batch_job_zero_shot_status = client.batches.retrieve(batch_job_zero_shot_id)\n",
    "batch_job_cot_status = client.batches.retrieve(batch_job_cot_id)\n",
    "batch_job_cot_few_shot_status = client.batches.retrieve(batch_job_cot_few_shot_id)\n",
    "\n",
    "print(\"Zero-shot batch job status:\", batch_job_zero_shot_status)\n",
    "print(\"Chain-of-thought batch job status:\", batch_job_cot_status)\n",
    "print(\"Chain-of-thought few-shot batch job status:\", batch_job_cot_few_shot_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa6e38c-5936-4531-aadf-46bc3c700a96",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ba697f-b75d-48cf-8b63-f7786e1b301b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "api_key = #“Enter your own API code”\n",
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ecac40-c72b-44ac-8a67-d34a0a40c89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zero-shot: Genre\n",
    "\n",
    "zero_shot_output_file_id = #file id\n",
    "\n",
    "result_zeroshot = client.files.content(zero_shot_output_file_id).content\n",
    "result_zeroshot_file_name = \"batch_job_zeroshot_Genre_results.jsonl\"\n",
    "\n",
    "with open(result_zeroshot_file_name, \"w\") as file:\n",
    "    file.write(result_zeroshot.decode('utf-8'))\n",
    "    \n",
    "results_zeroshot = []\n",
    "with open(result_zeroshot_file_name, 'r') as file:\n",
    "    for line in file:\n",
    "        json_obj = json.loads(line.strip())\n",
    "        results_zeroshot.append(json_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba9ced3-1422-45f4-88fb-f33f717f7106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cot: Genre\n",
    "\n",
    "cot_output_file_id = #file id\n",
    "\n",
    "result_cot = client.files.content(cot_output_file_id).content\n",
    "result_cot_file_name = \"batch_job_cot_Genre_results.jsonl\"\n",
    "\n",
    "with open(result_cot_file_name, \"w\") as file:\n",
    "    file.write(result_cot.decode('utf-8'))\n",
    "    \n",
    "results_cot = []\n",
    "with open(result_cot_file_name, 'r') as file:\n",
    "    for line in file:\n",
    "        json_obj = json.loads(line.strip())\n",
    "        results_cot.append(json_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e067b0bd-5d44-4bf9-9b1a-1b7e9b9d57b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cot+few-shot: Genre\n",
    "\n",
    "cot_few_shot_output_file_id = #file id\n",
    "\n",
    "result_cot_few_shot = client.files.content(cot_few_shot_output_file_id).content\n",
    "result_cot_few_shot_file_name = \"batch_job_cot_fewshot_Genre_results.jsonl\"\n",
    "\n",
    "with open(result_cot_few_shot_file_name, \"w\") as file:\n",
    "    file.write(result_cot_few_shot.decode('utf-8'))\n",
    "    \n",
    "results_cot_few_shot = []\n",
    "with open(result_cot_few_shot_file_name, 'r') as file:\n",
    "    for line in file:\n",
    "        json_obj = json.loads(line.strip())\n",
    "        results_cot_few_shot.append(json_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc824f0-b9fe-4102-a4d0-7192b745828e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the JSONL Files and Create DataFrames\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Load the JSONL files\n",
    "files = {\n",
    "    \"zero_shot\": \"batch_job_zeroshot_Genre_results.jsonl\",\n",
    "    \"cot\": \"batch_job_cot_Genre_results.jsonl\",\n",
    "    \"cot_few_shot\": \"batch_job_cot_fewshot_Genre_results.jsonl\"\n",
    "}\n",
    "\n",
    "# Function to read JSONL file and return DataFrame\n",
    "def read_jsonl(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if line:  # Check if the line is not empty\n",
    "                try:\n",
    "                    json_obj = json.loads(line)\n",
    "                    # Extract the genre from the JSON object\n",
    "                    genre = json_obj['response']['body']['choices'][0]['message']['content'].replace(\"Genre: \", \"\").strip()\n",
    "                    # Append the genre to the data list\n",
    "                    data.append({'genre': genre})\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"Error decoding JSON on line: {line}\")\n",
    "                    print(f\"Error message: {str(e)}\")\n",
    "                except KeyError as e:\n",
    "                    print(f\"Missing key in JSON on line: {line}\")\n",
    "                    print(f\"Error message: {str(e)}\")\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Load the data into DataFrames\n",
    "dfs = {key: read_jsonl(path) for key, path in files.items()}\n",
    "\n",
    "# Align DataFrames by index (assuming they have the same number of rows)\n",
    "aligned_df = pd.concat(dfs.values(), axis=1, keys=dfs.keys())\n",
    "\n",
    "# Flatten the multi-level column index\n",
    "aligned_df.columns = ['_'.join(col).strip() for col in aligned_df.columns.values]\n",
    "\n",
    "# Load the ground truth\n",
    "ground_truth_df = pd.read_csv('Billboard_yearly_filtered.csv')\n",
    "\n",
    "# Merge the ground truth with the predictions\n",
    "merged_df = pd.concat([ground_truth_df, aligned_df], axis=1)\n",
    "\n",
    "# Verify the column names in the merged DataFrame\n",
    "print(merged_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af833e9-b5bf-48aa-b566-53b2f340fc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Predictions with Ground Truth\n",
    "\n",
    "# Function to clean and split genre strings\n",
    "def clean_and_split_genres(genre_str):\n",
    "    genre_str = genre_str.replace('[', '').replace(']', '').replace(\"'\", \"\")\n",
    "    return set(genre_str.split(', '))\n",
    "\n",
    "# Function to calculate overlap ratio\n",
    "def calculate_overlap_ratio(predicted_genres, true_genres):\n",
    "    predicted_set = clean_and_split_genres(predicted_genres)\n",
    "    true_set = clean_and_split_genres(true_genres)\n",
    "    intersection = predicted_set.intersection(true_set)\n",
    "    return len(intersection) / len(true_set) if true_set else 0\n",
    "\n",
    "# Function to calculate exact match accuracy\n",
    "def calculate_exact_match(predicted_genres, true_genres):\n",
    "    predicted_set = clean_and_split_genres(predicted_genres)\n",
    "    true_set = clean_and_split_genres(true_genres)\n",
    "    return 1 if not predicted_set.isdisjoint(true_set) else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1b29bf-b620-46df-8ab8-5ec86dfcd08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the ground truth with the predictions\n",
    "merged_df = pd.concat([ground_truth_df, aligned_df], axis=1)\n",
    "\n",
    "# Initialize results list\n",
    "results_summary = []\n",
    "\n",
    "# Initialize totals for averaging\n",
    "total_metrics = {\n",
    "    'zero_shot_overlap_ratio': 0,\n",
    "    'zero_shot_exact_match': 0,\n",
    "    'cot_overlap_ratio': 0,\n",
    "    'cot_exact_match': 0,\n",
    "    'cot_few_shot_overlap_ratio': 0,\n",
    "    'cot_few_shot_exact_match': 0,\n",
    "    'total_rows': 0\n",
    "}\n",
    "\n",
    "# Iterate through the merged dataframe and calculate accuracy\n",
    "for _, row in merged_df.iterrows():\n",
    "    true_genre = row['Genre']  # Assuming the ground truth genre column is named 'Genre'\n",
    "    \n",
    "    # Zero-shot\n",
    "    predicted_genre = row['zero_shot_genre']\n",
    "    total_metrics['zero_shot_overlap_ratio'] += calculate_overlap_ratio(predicted_genre, true_genre)\n",
    "    total_metrics['zero_shot_exact_match'] += calculate_exact_match(predicted_genre, true_genre)\n",
    "    \n",
    "    # Chain-of-thought\n",
    "    predicted_genre = row['cot_genre']\n",
    "    total_metrics['cot_overlap_ratio'] += calculate_overlap_ratio(predicted_genre, true_genre)\n",
    "    total_metrics['cot_exact_match'] += calculate_exact_match(predicted_genre, true_genre)\n",
    "    \n",
    "    # Chain-of-thought few-shot\n",
    "    predicted_genre = row['cot_few_shot_genre']\n",
    "    total_metrics['cot_few_shot_overlap_ratio'] += calculate_overlap_ratio(predicted_genre, true_genre)\n",
    "    total_metrics['cot_few_shot_exact_match'] += calculate_exact_match(predicted_genre, true_genre)\n",
    "    \n",
    "    total_metrics['total_rows'] += 1\n",
    "\n",
    "# Calculate final averages\n",
    "total_average_metrics = {key: value / total_metrics['total_rows'] for key, value in total_metrics.items() if key != 'total_rows'}\n",
    "\n",
    "# Append final summary row\n",
    "results_summary.append({\n",
    "    'Zero-shot Overlap Ratio': total_average_metrics['zero_shot_overlap_ratio'],\n",
    "    'Zero-shot Exact Match': total_average_metrics['zero_shot_exact_match'],\n",
    "    'CoT Overlap Ratio': total_average_metrics['cot_overlap_ratio'],\n",
    "    'CoT Exact Match': total_average_metrics['cot_exact_match'],\n",
    "    'CoT Few-shot Overlap Ratio': total_average_metrics['cot_few_shot_overlap_ratio'],\n",
    "    'CoT Few-shot Exact Match': total_average_metrics['cot_few_shot_exact_match']\n",
    "})\n",
    "\n",
    "# Create summary DataFrame\n",
    "results_summary_df = pd.DataFrame(results_summary)\n",
    "\n",
    "# Save the results to a new CSV file\n",
    "results_summary_df.to_csv('Billboard_Genre_GPT_4o_experiment_results_1990-2023.csv', index=False)\n",
    "\n",
    "print(results_summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c33bcd-db03-4b6b-a760-3395a356e874",
   "metadata": {},
   "source": [
    "## Monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181a4344-0fc8-49fb-a6f5-aa1a3c54e279",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Load the unique genre list from the CSV file using raw string\n",
    "genre_df = pd.read_csv(r'[EN] Unique Genre Counts.csv')\n",
    "\n",
    "# Assuming the genre list is in a column named 'Genre'\n",
    "unique_genres = genre_df['Genre'].tolist()\n",
    "genre_list_str = ', '.join(unique_genres)\n",
    "print(genre_list_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c438091d-f584-44cd-8393-56ab3b7fa77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Function to prepare the zero-shot payload\n",
    "def prepare_zero_shot_payload(lyrics, unique_genres):\n",
    "    genre_list_str = ', '.join(unique_genres)\n",
    "    \n",
    "    prompt = (\n",
    "        f\"Here is a list of unique music genres: [{genre_list_str}].\\n\\n\"\n",
    "        f\"Lyrics: '{lyrics}'\\n\\n\"\n",
    "        f\"Say nothing but the Genre as Genre: {{the output}}\\n\\n\"\n",
    "        f\"Output example: Genre: [pop, r&b, hip hop]\\n\\n\"\n",
    "        f\"Genres: \"\n",
    "    )\n",
    "    \n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    \n",
    "    payload = {\n",
    "        \"model\": \"gpt-4o\",\n",
    "        \"messages\": messages,\n",
    "        \"max_tokens\": 40,\n",
    "        \"temperature\": 0\n",
    "    }\n",
    "    \n",
    "    return payload\n",
    "\n",
    "# Function to prepare the chain-of-thought prompt payload\n",
    "def prepare_cot_payload(lyrics, unique_genres):\n",
    "    genre_list_str = ', '.join(unique_genres)\n",
    "    \n",
    "    prompt = (\n",
    "        f\"Here is a list of unique music genres: [{genre_list_str}].\\n\\n\"\n",
    "        f\"Based on the lyrics provided, identify the genres.\\n\\n\"\n",
    "        f\"Lyrics: '{lyrics}'\\n\\n\"\n",
    "        f\"Say nothing but the Genre as Genre: {{the output}}\\n\\n\"\n",
    "        f\"Output example: Genre: [pop, r&b, hip hop]\\n\\n\"\n",
    "        f\"Genre:\"\n",
    "    )\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    \n",
    "    payload = {\n",
    "        \"model\": \"gpt-4o\",\n",
    "        \"messages\": messages,\n",
    "        \"max_tokens\": 40,\n",
    "        \"temperature\": 0\n",
    "    }\n",
    "    \n",
    "    return payload\n",
    "\n",
    "\n",
    "# Function to prepare the chain-of-thought few-shot prompt payload\n",
    "def prepare_cot_few_shot_payload(lyrics, unique_genres):\n",
    "    genre_list_str = ', '.join(unique_genres)\n",
    "    \n",
    "    example_lyrics = (\n",
    "        \"I'd like to say we gave it a try\\n\"\n",
    "        \"I'd like to blame it all on life\\n\"\n",
    "        \"Maybe we just weren't right\\n\"\n",
    "        \"But that's a lie, that's a lie\\n\\n\"\n",
    "\n",
    "        \"And we can deny it as much as we want\\n\"\n",
    "        \"But in time, our feelings will show\\n\"\n",
    "        \"'Cause sooner or later, we'll wonder why we gave up\\n\"\n",
    "        \"The truth is everyone knows, oh\\n\\n\"\n",
    "\n",
    "        \"Almost, almost is never enough\\n\"\n",
    "        \"So close to being in love\\n\"\n",
    "        \"If I would have known that you wanted me the way I wanted you\\n\"\n",
    "        \"Then maybe we wouldn't be two worlds apart (Ah)\\n\"\n",
    "        \"But right here in each other's arms\\n\"\n",
    "        \"And we almost, we almost knew what love was\\n\"\n",
    "        \"But almost is never enough (Ah)\\n\\n\"\n",
    "\n",
    "        \"If I could change the world overnight (Ah)\\n\"\n",
    "        \"There'd be no such thing as goodbye (Ah)\\n\"\n",
    "        \"You'd be standing right where you were (Ah)\\n\"\n",
    "        \"And we'd get the chance we deserve, oh (Ah)\\n\"\n",
    "        \"See upcoming pop shows\\n\"\n",
    "        \"Get tickets for your favorite artists\\n\\n\"\n",
    "\n",
    "        \"Try to deny it as much as you want\\n\"\n",
    "        \"But in time, our feelings will show (Ah)\\n\"\n",
    "        \"'Cause sooner or later, we'll wonder why we gave up\\n\"\n",
    "        \"The truth is everyone knows (Ah)\\n\\n\"\n",
    "\n",
    "        \"Almost, almost is never enough\\n\"\n",
    "        \"So close to being in love\\n\"\n",
    "        \"If I would have known that you wanted me the way I wanted you, woah\\n\"\n",
    "        \"Then maybe we wouldn't be two worlds apart\\n\"\n",
    "        \"But right here (Right here) in each other's arms\\n\"\n",
    "        \"And we almost, we almost knew what love was\\n\"\n",
    "        \"But almost is never enough\\n\\n\"\n",
    "\n",
    "        \"Huh (Woah; Huh, baby), huh, baby (Mm)\\n\"\n",
    "        \"You know (You know)\\n\"\n",
    "        \"You know, baby (Huh, baby; Huh)\\n\"\n",
    "        \"Almost (Baby, baby, baby) is never enough, baby\\n\"\n",
    "        \"You know (Hm-hm), ooh-yeah\\n\\n\"\n",
    "\n",
    "        \"And we can deny it as much as we want\\n\"\n",
    "        \"But in time, our feelings will show\\n\"\n",
    "        \"'Cause sooner or later, we'll wonder why we gave up\\n\"\n",
    "        \"The truth is (Truth is) everyone knows (Oh)\\n\\n\"\n",
    "\n",
    "        \"Almost (Almost), almost is never enough (Is never enough, baby)\\n\"\n",
    "        \"(We were close) So close to being in love (So close)\\n\"\n",
    "        \"If I would have known that you wanted me (That you wanted me)\\n\"\n",
    "        \"The way I wanted you, babe\\n\"\n",
    "        \"Then maybe we wouldn't be two worlds apart\\n\"\n",
    "        \"But right here in each other's arms\\n\"\n",
    "        \"And we almost, we almost knew what love was (Baby)\\n\"\n",
    "        \"But almost is never enough\\n\\n\"\n",
    "        \"[Outro: Ariana Grande, Both & Nathan Sykes]\\n\"\n",
    "        \"Huh, huh, baby (Almost)\\n\"\n",
    "        \"You know (Hey), you know, baby (Oh)\\n\"\n",
    "        \"Almost (Never)\\n\"\n",
    "        \"Is never enough, baby (Never)\\n\"\n",
    "        \"You know (Ooh), hey\\n\"\n",
    "    )\n",
    "    example_genres = \"pop, soul\"\n",
    "\n",
    "    prompt = (\n",
    "        f\"Here is a list of unique music genres: [{genre_list_str}].\\n\\n\"\n",
    "        \n",
    "        f\"Example:\\n\\n\"\n",
    "        f\"Lyrics: '{example_lyrics}'\\n\\n\"\n",
    "        f\"Genre: {example_genres}\\n\\n\"\n",
    "\n",
    "        f\"Now, based on the provided lyrics, identify the genres.\\n\\n\"\n",
    "        f\"Lyrics: '{lyrics}'\\n\\n\"\n",
    "        f\"Say nothing but the Genre as Genre: {{the output}}\\n\\n\"\n",
    "        f\"Output example: Genre: [pop, r&b, hip hop]\\n\\n\"\n",
    "        f\"Genre:\"\n",
    "    )\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    \n",
    "    payload = {\n",
    "        \"model\": \"gpt-4o\",\n",
    "        \"messages\": messages,\n",
    "        \"max_tokens\": 40,\n",
    "        \"temperature\": 0\n",
    "    }\n",
    "    \n",
    "    return payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0077b03d-8c1e-4c6e-8b16-61b122050739",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = #“Enter your own API code”\n",
    "\n",
    "def make_request(payload, api_key):\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {api_key}\"\n",
    "    }\n",
    "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "    response_data = response.json()\n",
    "    return response_data\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('Billboard_weekly_filtered.csv')\n",
    "\n",
    "# Prepare the results dataframe\n",
    "results = {\n",
    "    'Title': [],\n",
    "    'Artist': [],\n",
    "    'zero_shot_Genre': [],\n",
    "    'cot_Genre': [],\n",
    "    'cot_few_shot_Genre': [],\n",
    "}\n",
    "\n",
    "result_keys = ['Title', 'Artist', 'zero_shot_Genre', 'cot_Genre','cot_few_shot_Genre']\n",
    "\n",
    "# Iterate over each row in the dataframe\n",
    "count = 0\n",
    "for index, row in df.iterrows():\n",
    "    count += 1\n",
    "    if count % 100 == 0:\n",
    "        url = f'2024 Lyrics, Genre, Description Billboard Results {count}_prompt(10).csv'     ############## 여기 변경 필요\n",
    "        results_df = pd.DataFrame(results)\n",
    "        results_df.to_csv(url, index=False)\n",
    "        print(f\"Results saved to '{url}'\")\n",
    "        for keys in result_keys:\n",
    "            results[keys].clear()\n",
    "    \n",
    "    title = row['Title']\n",
    "    artist = row['Artist']\n",
    "    lyrics = row['lyrics']\n",
    "\n",
    "    # Zero-shot\n",
    "    payload = prepare_zero_shot_payload(lyrics, unique_genres)\n",
    "    response = make_request(payload, api_key)\n",
    "    zero_shot_response = response['choices'][0]['message']['content'].strip()\n",
    "    \n",
    "    # Extract genre and description\n",
    "    zero_shot_genre = zero_shot_response.split(\"Description:\")[0].replace(\"Genres:\", \"\").replace(\"Genre:\", \"\").strip()\n",
    "    \n",
    "    # Chain-of-thought\n",
    "    payload = prepare_cot_payload(lyrics, unique_genres)\n",
    "    response = make_request(payload, api_key)\n",
    "    cot_response = response['choices'][0]['message']['content'].strip()\n",
    "    \n",
    "    # Extract genre and description\n",
    "    cot_genre = cot_response.split(\"Description:\")[0].replace(\"Genres:\", \"\").replace(\"Genre:\", \"\").strip()\n",
    "    \n",
    "    # Chain-of-thought few-shot\n",
    "    payload = prepare_cot_few_shot_payload(lyrics, unique_genres)\n",
    "    response = make_request(payload, api_key)\n",
    "    cot_few_shot_response = response['choices'][0]['message']['content'].strip()\n",
    "    \n",
    "    # Extract genre and description\n",
    "    cot_few_shot_genre = cot_few_shot_response.split(\"Description:\")[0].replace(\"Genres:\", \"\").replace(\"Genre:\", \"\").strip()\n",
    "\n",
    "    # Save the results\n",
    "    results['Title'].append(title)\n",
    "    results['Artist'].append(artist)\n",
    "    results['zero_shot_Genre'].append(zero_shot_genre)\n",
    "    results['cot_Genre'].append(cot_genre)\n",
    "    results['cot_few_shot_Genre'].append(cot_few_shot_genre)\n",
    "\n",
    "# Convert the results to a dataframe\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n",
    "\n",
    "# Save the results to a new CSV file\n",
    "results_df.to_csv('2024 Lyrics, Genre, Description Billboard Results 175.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7925fb-136b-4fc9-b958-c346a0cc1bc6",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f757c9d-6953-4e25-89ae-7593fd831fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "\n",
    "# Function to clean and split genre strings\n",
    "def clean_and_split_genres(genre_str):\n",
    "    genre_str = genre_str.replace('[', '').replace(']', '').replace(\"'\", \"\")\n",
    "    return set(genre_str.split(', '))\n",
    "\n",
    "# Function to calculate overlap ratio\n",
    "def calculate_overlap_ratio(predicted_genres, true_genres):\n",
    "    predicted_set = clean_and_split_genres(predicted_genres)\n",
    "    true_set = clean_and_split_genres(true_genres)\n",
    "    intersection = predicted_set.intersection(true_set)\n",
    "    return len(intersection) / len(true_set) if true_set else 0\n",
    "\n",
    "# Function to calculate exact match accuracy\n",
    "def calculate_exact_match(predicted_genres, true_genres):\n",
    "    predicted_set = clean_and_split_genres(predicted_genres)\n",
    "    true_set = clean_and_split_genres(true_genres)\n",
    "    return 1 if not predicted_set.isdisjoint(true_set) else 0\n",
    "\n",
    "# Load the ground truth descriptions\n",
    "ground_truth_df = pd.read_csv('Billboard_weekly_filtered.csv')\n",
    "\n",
    "# Initialize results list\n",
    "results_summary = []\n",
    "\n",
    "# Initialize totals for averaging\n",
    "total_metrics = {\n",
    "    'zero_shot_overlap_ratio': 0,\n",
    "    'zero_shot_exact_match': 0,\n",
    "    'cot_overlap_ratio': 0,\n",
    "    'cot_exact_match': 0,\n",
    "    'cot_few_shot_overlap_ratio': 0,\n",
    "    'cot_few_shot_exact_match': 0,\n",
    "    'total_files': 0,\n",
    "    'total_rows': 0\n",
    "}\n",
    "\n",
    "# Get list of result files\n",
    "result_files = sorted(glob.glob('2024 Lyrics, Genre, Description Billboard Results 100.csv') + \n",
    "                      glob.glob('2024 Lyrics, Genre, Description Billboard Results 175.csv'))\n",
    "\n",
    "# Iterate through the result files\n",
    "for result_file in result_files:\n",
    "    # Load the results\n",
    "    results_df = pd.read_csv(result_file)\n",
    "    \n",
    "    # Merge the dataframes on Title and Artist\n",
    "    merged_df = results_df.merge(ground_truth_df, on=['Title', 'Artist'])\n",
    "    \n",
    "    # Initialize variables to accumulate the correct predictions for this file\n",
    "    file_metrics = {\n",
    "        'zero_shot_overlap_ratio': 0,\n",
    "        'zero_shot_exact_match': 0,\n",
    "        'cot_overlap_ratio': 0,\n",
    "        'cot_exact_match': 0,\n",
    "        'cot_few_shot_overlap_ratio': 0,\n",
    "        'cot_few_shot_exact_match': 0,\n",
    "        'n': len(merged_df)\n",
    "    }\n",
    "    \n",
    "    # Iterate through the merged dataframe and calculate accuracy\n",
    "    for i, row in merged_df.iterrows():\n",
    "        true_genre = row['Genre']  # Assuming the ground truth genre column is named 'Genre'\n",
    "        \n",
    "        # Zero-shot\n",
    "        predicted_genre = row['zero_shot_Genre']\n",
    "        file_metrics['zero_shot_overlap_ratio'] += calculate_overlap_ratio(predicted_genre, true_genre)\n",
    "        file_metrics['zero_shot_exact_match'] += calculate_exact_match(predicted_genre, true_genre)\n",
    "        \n",
    "        # Chain-of-thought\n",
    "        predicted_genre = row['cot_Genre']\n",
    "        file_metrics['cot_overlap_ratio'] += calculate_overlap_ratio(predicted_genre, true_genre)\n",
    "        file_metrics['cot_exact_match'] += calculate_exact_match(predicted_genre, true_genre)\n",
    "        \n",
    "        # Chain-of-thought few-shot\n",
    "        predicted_genre = row['cot_few_shot_Genre']\n",
    "        file_metrics['cot_few_shot_overlap_ratio'] += calculate_overlap_ratio(predicted_genre, true_genre)\n",
    "        file_metrics['cot_few_shot_exact_match'] += calculate_exact_match(predicted_genre, true_genre)\n",
    "    \n",
    "    # Calculate average overlap ratio as accuracy for this file\n",
    "    for key in file_metrics:\n",
    "        if key != 'n':\n",
    "            file_metrics[key] /= file_metrics['n'] if file_metrics['n'] > 0 else 1\n",
    "    \n",
    "    # Extract file count from the filename using regex\n",
    "    match = re.search(r'(\\d+)_prompt\\(5\\)', result_file)\n",
    "    file_count = int(match.group(1)) if match else None\n",
    "    \n",
    "    # Append results to summary\n",
    "    results_summary.append({\n",
    "        'File Count': file_count,\n",
    "        'Zero-shot Overlap Ratio': file_metrics['zero_shot_overlap_ratio'],\n",
    "        'Zero-shot Exact Match': file_metrics['zero_shot_exact_match'],\n",
    "        'CoT Overlap Ratio': file_metrics['cot_overlap_ratio'],\n",
    "        'CoT Exact Match': file_metrics['cot_exact_match'],\n",
    "        'CoT Few-shot Overlap Ratio': file_metrics['cot_few_shot_overlap_ratio'],\n",
    "        'CoT Few-shot Exact Match': file_metrics['cot_few_shot_exact_match']\n",
    "    })\n",
    "    \n",
    "    # Accumulate totals for final summary\n",
    "    for key in total_metrics:\n",
    "        if key in file_metrics:\n",
    "            total_metrics[key] += file_metrics[key] * file_metrics['n']  # Sum the ratios back as counts\n",
    "        if key == 'total_rows':\n",
    "            total_metrics[key] += file_metrics['n']\n",
    "    \n",
    "    total_metrics['total_files'] += 1\n",
    "\n",
    "# Calculate final averages\n",
    "total_average_metrics = {}\n",
    "for key in total_metrics:\n",
    "    if key.startswith('total'):\n",
    "        continue\n",
    "    total_average_metrics[key] = total_metrics[key] / total_metrics['total_rows'] if total_metrics['total_rows'] > 0 else 0\n",
    "\n",
    "# Append final summary row\n",
    "results_summary.append({\n",
    "    'File Count': 'Total Average',\n",
    "    'Zero-shot Overlap Ratio': total_average_metrics['zero_shot_overlap_ratio'],\n",
    "    'Zero-shot Exact Match': total_average_metrics['zero_shot_exact_match'],\n",
    "    'CoT Overlap Ratio': total_average_metrics['cot_overlap_ratio'],\n",
    "    'CoT Exact Match': total_average_metrics['cot_exact_match'],\n",
    "    'CoT Few-shot Overlap Ratio': total_average_metrics['cot_few_shot_overlap_ratio'],\n",
    "    'CoT Few-shot Exact Match': total_average_metrics['cot_few_shot_exact_match']\n",
    "})\n",
    "\n",
    "results_summary_df = pd.DataFrame(results_summary)\n",
    "\n",
    "# Sort the DataFrame by the File Count, handling the 'Total Average' row separately\n",
    "results_summary_df['File Count'] = results_summary_df['File Count'].apply(lambda x: float('inf') if x == 'Total Average' else x)\n",
    "results_summary_df = results_summary_df.sort_values(by='File Count').reset_index(drop=True)\n",
    "results_summary_df['File Count'] = results_summary_df['File Count'].apply(lambda x: 'Total Average' if x == float('inf') else x)\n",
    "\n",
    "# Save the results to a new CSV file\n",
    "results_summary_df.to_csv('Billboard_Genre_GPT_4o_experiment_results_2024.csv', index=False)\n",
    "\n",
    "print(results_summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282574d4-e6b9-45d4-9ad9-ff2da3f0b79f",
   "metadata": {},
   "source": [
    "# Billboard - Song Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78f4d6e-085e-48bc-a1e3-ae8e37cf44ec",
   "metadata": {},
   "source": [
    "## Yearly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceebc8f2-fb13-4909-bb30-917a3ba3b3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import requests\n",
    "from openai import OpenAI\n",
    "\n",
    "# Function to prepare the zero-shot payload\n",
    "def prepare_zero_shot_payload(lyrics):  \n",
    "    prompt = (\n",
    "        f\"Say nothing but the Description as Description: {{the output}}\\n\\n\"\n",
    "        f\"Output example: Description: The song explores themes of love and heartbreak.\\n\\n\"\n",
    "        f\"Lyrics: '{lyrics}'\\n\\n\"\n",
    "        f\"Description:\"\n",
    "    )\n",
    "    \n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    \n",
    "    payload = {\n",
    "        \"model\": \"gpt-4o\",\n",
    "        \"messages\": messages,\n",
    "        \"max_tokens\": 300,\n",
    "        \"temperature\": 0\n",
    "    }\n",
    "    \n",
    "    return payload\n",
    "\n",
    "# Function to prepare the chain-of-thought prompt payload\n",
    "def prepare_cot_payload(lyrics):\n",
    "    prompt = (\n",
    "        f\"Based on the lyrics provided, write a brief description of the song.\\n\\n\"\n",
    "        f\"Include the possible song title and artist name in the description.\\n\\n\"\n",
    "        f\"Say nothing but the Description as Description: {{the output}}\\n\\n\"\n",
    "        f\"Output example: Description: Honeymoon Avenue by Ariana Grande is about knowing you are at the end of a relationship and wishing it could not be the end and go back to the beginning and start over. \\n\\n\"\n",
    "        f\"Lyrics: '{lyrics}'\\n\\n\"\n",
    "        f\"Description:\"\n",
    "    )\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    \n",
    "    payload = {\n",
    "        \"model\": \"gpt-4o\",\n",
    "        \"messages\": messages,\n",
    "        \"max_tokens\": 300,\n",
    "        \"temperature\": 0\n",
    "    }\n",
    "    \n",
    "    return payload\n",
    "\n",
    "# Function to prepare the chain-of-thought few-shot prompt payload\n",
    "def prepare_cot_few_shot_payload(lyrics):\n",
    "    \n",
    "    example_lyrics = (\n",
    "        \"I'd like to say we gave it a try\\n\"\n",
    "        \"I'd like to blame it all on life\\n\"\n",
    "        \"Maybe we just weren't right\\n\"\n",
    "        \"But that's a lie, that's a lie\\n\\n\"\n",
    "\n",
    "        \"And we can deny it as much as we want\\n\"\n",
    "        \"But in time, our feelings will show\\n\"\n",
    "        \"'Cause sooner or later, we'll wonder why we gave up\\n\"\n",
    "        \"The truth is everyone knows, oh\\n\\n\"\n",
    "\n",
    "        \"Almost, almost is never enough\\n\"\n",
    "        \"So close to being in love\\n\"\n",
    "        \"If I would have known that you wanted me the way I wanted you\\n\"\n",
    "        \"Then maybe we wouldn't be two worlds apart (Ah)\\n\"\n",
    "        \"But right here in each other's arms\\n\"\n",
    "        \"And we almost, we almost knew what love was\\n\"\n",
    "        \"But almost is never enough (Ah)\\n\\n\"\n",
    "\n",
    "        \"If I could change the world overnight (Ah)\\n\"\n",
    "        \"There'd be no such thing as goodbye (Ah)\\n\"\n",
    "        \"You'd be standing right where you were (Ah)\\n\"\n",
    "        \"And we'd get the chance we deserve, oh (Ah)\\n\"\n",
    "        \"See upcoming pop shows\\n\"\n",
    "        \"Get tickets for your favorite artists\\n\\n\"\n",
    "\n",
    "        \"Try to deny it as much as you want\\n\"\n",
    "        \"But in time, our feelings will show (Ah)\\n\"\n",
    "        \"'Cause sooner or later, we'll wonder why we gave up\\n\"\n",
    "        \"The truth is everyone knows (Ah)\\n\\n\"\n",
    "\n",
    "        \"Almost, almost is never enough\\n\"\n",
    "        \"So close to being in love\\n\"\n",
    "        \"If I would have known that you wanted me the way I wanted you, woah\\n\"\n",
    "        \"Then maybe we wouldn't be two worlds apart\\n\"\n",
    "        \"But right here (Right here) in each other's arms\\n\"\n",
    "        \"And we almost, we almost knew what love was\\n\"\n",
    "        \"But almost is never enough\\n\\n\"\n",
    "\n",
    "        \"Huh (Woah; Huh, baby), huh, baby (Mm)\\n\"\n",
    "        \"You know (You know)\\n\"\n",
    "        \"You know, baby (Huh, baby; Huh)\\n\"\n",
    "        \"Almost (Baby, baby, baby) is never enough, baby\\n\"\n",
    "        \"You know (Hm-hm), ooh-yeah\\n\\n\"\n",
    "\n",
    "        \"And we can deny it as much as we want\\n\"\n",
    "        \"But in time, our feelings will show\\n\"\n",
    "        \"'Cause sooner or later, we'll wonder why we gave up\\n\"\n",
    "        \"The truth is (Truth is) everyone knows (Oh)\\n\\n\"\n",
    "\n",
    "        \"Almost (Almost), almost is never enough (Is never enough, baby)\\n\"\n",
    "        \"(We were close) So close to being in love (So close)\\n\"\n",
    "        \"If I would have known that you wanted me (That you wanted me)\\n\"\n",
    "        \"The way I wanted you, babe\\n\"\n",
    "        \"Then maybe we wouldn't be two worlds apart\\n\"\n",
    "        \"But right here in each other's arms\\n\"\n",
    "        \"And we almost, we almost knew what love was (Baby)\\n\"\n",
    "        \"But almost is never enough\\n\\n\"\n",
    "        \"[Outro: Ariana Grande, Both & Nathan Sykes]\\n\"\n",
    "        \"Huh, huh, baby (Almost)\\n\"\n",
    "        \"You know (Hey), you know, baby (Oh)\\n\"\n",
    "        \"Almost (Never)\\n\"\n",
    "        \"Is never enough, baby (Never)\\n\"\n",
    "        \"You know (Ooh), hey\\n\"\n",
    "    )\n",
    "\n",
    "    example_description = (\n",
    "        \"On the collaborative track “Almost Is Never Enough,” Ariana Grande & Nathan Sykes play a couple who had a relationship that hadn’t gone right. \"\n",
    "        \"Ariana would like to say things were going well but she knows that’s a lie and like the title states, almost is never enough to make the relationship work; you need to put full effort in. \"\n",
    "        \"Both of them state that they didn’t feel the relationship while in it, but the mood of the song and lyrics suggest that they both want to either reconnect or they simply just miss better times.\\n\\n\"\n",
    "        \"At the time of the song’s release, Nathan and Ariana were dating. Unfortunately, their relationship ended a few months later.\"\n",
    "    )\n",
    "    \n",
    "\n",
    "    prompt = (\n",
    "        f\"Example:\\n\\n\"\n",
    "        f\"Lyrics: '{example_lyrics}'\\n\\n\"\n",
    "        f\"Genre: {example_description}\\n\\n\"\n",
    "\n",
    "        f\"Now, based on the provided lyrics, write a brief description of the song.\\n\\n\"\n",
    "        f\"Include the possible song title and artist name in the description.\\n\\n\"\n",
    "        f\"Say nothing but the Description as Description: {{the output}}\\n\\n\"\n",
    "        f\"Output example: Description: Honeymoon Avenue by Ariana Grande is about knowing you are at the end of a relationship and wishing it could not be the end and go back to the beginning and start over. \\n\\n\"\n",
    "        f\"Lyrics: '{lyrics}'\\n\\n\"\n",
    "        f\"Description:\"\n",
    "    )\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    \n",
    "    payload = {\n",
    "        \"model\": \"gpt-4o\",\n",
    "        \"messages\": messages,\n",
    "        \"max_tokens\": 300,\n",
    "        \"temperature\": 0\n",
    "    }\n",
    "    \n",
    "    return payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38ba866-58ee-469d-b635-be42e933a550",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = # \"Enter your API code\"\n",
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb76b918-4128-48fd-9ba0-b2299694d1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Billboard_yearly_filtered.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b48cbd-af89-4234-86a3-77596470202a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the tasks for each method\n",
    "tasks_zero_shot = []\n",
    "tasks_cot = []\n",
    "tasks_cot_few_shot = []\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    lyrics = row['lyrics']\n",
    "    \n",
    "    # Zero-shot task\n",
    "    payload_zero_shot = prepare_zero_shot_payload(lyrics)\n",
    "    task_zero_shot = {\n",
    "        \"custom_id\": f\"zero_shot_{i}\",\n",
    "        \"method\": \"POST\",\n",
    "        \"url\": \"/v1/chat/completions\",\n",
    "        \"body\": payload_zero_shot\n",
    "    }\n",
    "    tasks_zero_shot.append(task_zero_shot)\n",
    "    \n",
    "    # Chain-of-thought task\n",
    "    payload_cot = prepare_cot_payload(lyrics)\n",
    "    task_cot = {\n",
    "        \"custom_id\": f\"cot_{i}\",\n",
    "        \"method\": \"POST\",\n",
    "        \"url\": \"/v1/chat/completions\",\n",
    "        \"body\": payload_cot\n",
    "    }\n",
    "    tasks_cot.append(task_cot)\n",
    "    \n",
    "    # Chain-of-thought few-shot task\n",
    "    payload_cot_few_shot = prepare_cot_few_shot_payload(lyrics)\n",
    "    task_cot_few_shot = {\n",
    "        \"custom_id\": f\"cot_few_shot_{i}\",\n",
    "        \"method\": \"POST\",\n",
    "        \"url\": \"/v1/chat/completions\",\n",
    "        \"body\": payload_cot_few_shot\n",
    "    }\n",
    "    tasks_cot_few_shot.append(task_cot_few_shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65854f8-0ab4-4ec2-9349-d544a45ba610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save tasks to JSONL files\n",
    "file_name_zero_shot = \"batch_zero_shot_description_ver2.jsonl\"\n",
    "file_name_cot = \"batch_cot_description_ver2.jsonl\"\n",
    "file_name_cot_few_shot = \"batch_cot_few_shot_description_ver2.jsonl\"\n",
    "\n",
    "def save_tasks_to_file(file_name, tasks):\n",
    "    with open(file_name, 'w') as file:\n",
    "        for task in tasks:\n",
    "            file.write(json.dumps(task) + '\\n')\n",
    "\n",
    "save_tasks_to_file(file_name_zero_shot, tasks_zero_shot)\n",
    "save_tasks_to_file(file_name_cot, tasks_cot)\n",
    "save_tasks_to_file(file_name_cot_few_shot, tasks_cot_few_shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50598bf-c426-4a63-bb21-cc6c94f9e04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the files\n",
    "batch_file_zero_shot = client.files.create(file=open(file_name_zero_shot, \"rb\"), purpose=\"batch\")\n",
    "batch_file_cot = client.files.create(file=open(file_name_cot, \"rb\"), purpose=\"batch\")\n",
    "batch_file_cot_few_shot = client.files.create(file=open(file_name_cot_few_shot, \"rb\"), purpose=\"batch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ed3152-41b8-4c90-9c3c-b329e172b0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the batch jobs\n",
    "batch_job_zero_shot = client.batches.create(\n",
    "    input_file_id=batch_file_zero_shot.id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\"\n",
    ")\n",
    "\n",
    "batch_job_cot = client.batches.create(\n",
    "    input_file_id=batch_file_cot.id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\"\n",
    ")\n",
    "\n",
    "batch_job_cot_few_shot = client.batches.create(\n",
    "    input_file_id=batch_file_cot_few_shot.id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e44b261-ca93-4809-96c0-69c24dc22492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the status of the batch jobs\n",
    "batch_job_zero_shot_status = client.batches.retrieve(batch_job_zero_shot.id)\n",
    "batch_job_cot_status = client.batches.retrieve(batch_job_cot.id)\n",
    "batch_job_cot_few_shot_status = client.batches.retrieve(batch_job_cot_few_shot.id)\n",
    "\n",
    "print(\"Zero-shot batch job status:\", batch_job_zero_shot_status)\n",
    "print(\"Chain-of-thought batch job status:\", batch_job_cot_status)\n",
    "print(\"Chain-of-thought few-shot batch job status:\", batch_job_cot_few_shot_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c6ab06-81f7-4597-a371-2151f211d94b",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eda3659-0e16-4460-af14-cf6fc9c25339",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_shot_output_file_id = #output file id\n",
    "cot_output_file_id = #output file id\n",
    "cot_few_shot_output_file_id = #output file id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69d892a-4e54-438c-adad-8b18e675fa68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "api_key = # \"Enter your API code\"\n",
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb07a386-30cb-48d7-82cb-fcd3b9d093d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zero-shot: Description\n",
    "\n",
    "zero_shot_output_file_id = #output file id\n",
    "\n",
    "result_zeroshot = client.files.content(zero_shot_output_file_id).content\n",
    "result_zeroshot_file_name = \"batch_job_zeroshot_Description_results_ver2.jsonl\"\n",
    "\n",
    "with open(result_zeroshot_file_name, \"w\") as file:\n",
    "    file.write(result_zeroshot.decode('utf-8'))\n",
    "    \n",
    "results_zeroshot = []\n",
    "with open(result_zeroshot_file_name, 'r') as file:\n",
    "    for line in file:\n",
    "        json_obj = json.loads(line.strip())\n",
    "        results_zeroshot.append(json_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a7cca7-5213-4637-b857-3f034a4ccaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cot: Description\n",
    "\n",
    "cot_output_file_id = #output file id\n",
    "\n",
    "result_cot = client.files.content(cot_output_file_id).content\n",
    "result_cot_file_name = \"batch_job_cot_Description_results_ver2.jsonl\"\n",
    "\n",
    "with open(result_cot_file_name, \"w\") as file:\n",
    "    file.write(result_cot.decode('utf-8'))\n",
    "    \n",
    "results_cot = []\n",
    "with open(result_cot_file_name, 'r') as file:\n",
    "    for line in file:\n",
    "        json_obj = json.loads(line.strip())\n",
    "        results_cot.append(json_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a65ad2-f8d4-4cab-82de-c11138c678d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cot+few-shot: Description\n",
    "\n",
    "cot_few_shot_output_file_id = #output file id\n",
    "\n",
    "result_cot_few_shot = client.files.content(cot_few_shot_output_file_id).content\n",
    "result_cot_few_shot_file_name = \"batch_job_cot_fewshot_Description_results_ver2.jsonl\"\n",
    "\n",
    "with open(result_cot_few_shot_file_name, \"w\") as file:\n",
    "    file.write(result_cot_few_shot.decode('utf-8'))\n",
    "    \n",
    "results_cot_few_shot = []\n",
    "with open(result_cot_few_shot_file_name, 'r') as file:\n",
    "    for line in file:\n",
    "        json_obj = json.loads(line.strip())\n",
    "        results_cot_few_shot.append(json_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6cab09-1e01-4a16-913b-370c2b4a4ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Load the JSONL files\n",
    "files = {\n",
    "    \"zero_shot\": #file name,\n",
    "    \"cot\": #file name,\n",
    "    \"cot_few_shot\": # file name\n",
    "}\n",
    "\n",
    "# Function to read JSONL file and return DataFrame\n",
    "def read_jsonl(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if line:  # Check if the line is not empty\n",
    "                try:\n",
    "                    json_obj = json.loads(line)\n",
    "                    # Extract the description from the JSON object\n",
    "                    description = json_obj['response']['body']['choices'][0]['message']['content'].replace(\"Description: \", \"\").strip()\n",
    "                    # Append the description to the data list\n",
    "                    data.append({'description': description})\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"Error decoding JSON on line: {line}\")\n",
    "                    print(f\"Error message: {str(e)}\")\n",
    "                except KeyError as e:\n",
    "                    print(f\"Missing key in JSON on line: {line}\")\n",
    "                    print(f\"Error message: {str(e)}\")\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Load the data into DataFrames\n",
    "dfs = {key: read_jsonl(path) for key, path in files.items()}\n",
    "\n",
    "# Align DataFrames by index (assuming they have the same number of rows)\n",
    "aligned_df = pd.concat(dfs.values(), axis=1, keys=dfs.keys())\n",
    "\n",
    "# Flatten the multi-level column index\n",
    "aligned_df.columns = ['_'.join(col).strip() for col in aligned_df.columns.values]\n",
    "\n",
    "# Load the ground truth\n",
    "ground_truth_df = pd.read_csv('Billboard_yearly_filtered.csv')\n",
    "\n",
    "# Merge the ground truth with the predictions\n",
    "merged_df = pd.concat([ground_truth_df, aligned_df], axis=1)\n",
    "\n",
    "# Verify the column names in the merged DataFrame\n",
    "print(merged_df.columns.tolist())\n",
    "\n",
    "# Display the merged DataFrame\n",
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6294fe70-05f9-4cd1-aab5-52058e194945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize BERTScorer\n",
    "scorer = BERTScorer(lang=\"en\", rescale_with_baseline=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e47b4da-7d3c-4c8f-9a9b-831f1bfa80b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate scores\n",
    "def evaluate_using_rouge(reference, hypothesis):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
    "    scores = scorer.score(reference, hypothesis)\n",
    "    avg_scores = {\n",
    "        'rouge-1': scores['rouge1'],\n",
    "        'rouge-l': scores['rougeL']\n",
    "    }\n",
    "    return avg_scores\n",
    "\n",
    "def evaluate_using_bert_score(text, predicted_text, scorer):\n",
    "    P, R, F1 = scorer.score([text], [predicted_text])\n",
    "    return [P.mean().item(), R.mean().item(), F1.mean().item()]  # Calculate mean scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8622869b-6671-48b8-b3ad-ac29cff33194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main evaluation function\n",
    "def evaluation(merged_df, scorer):\n",
    "    methods = ['zero_shot', 'cot', 'cot_few_shot']\n",
    "    results_summary = []\n",
    "\n",
    "    for method in methods:\n",
    "        rouge_1_f = rouge_1_p = rouge_1_r = 0.0\n",
    "        rouge_L_f = rouge_L_p = rouge_L_r = 0.0\n",
    "        bert_P = bert_R = bert_F1 = 0.0\n",
    "        n = len(merged_df)\n",
    "\n",
    "        for i, row in merged_df.iterrows():\n",
    "            truth_description = row['description']  # Ground truth description\n",
    "            predict_description = row[f'{method}_description']  # Predicted description\n",
    "\n",
    "            rouge = evaluate_using_rouge(truth_description, predict_description)\n",
    "            bert = evaluate_using_bert_score(truth_description, predict_description, scorer)\n",
    "\n",
    "            rouge_1_f += rouge['rouge-1'].fmeasure\n",
    "            rouge_1_p += rouge['rouge-1'].precision\n",
    "            rouge_1_r += rouge['rouge-1'].recall\n",
    "            rouge_L_f += rouge['rouge-l'].fmeasure\n",
    "            rouge_L_p += rouge['rouge-l'].precision\n",
    "            rouge_L_r += rouge['rouge-l'].recall\n",
    "            bert_P += bert[0]\n",
    "            bert_R += bert[1]\n",
    "            bert_F1 += bert[2]\n",
    "\n",
    "        results_summary.append({\n",
    "            'method': method,\n",
    "            'rouge-1_f1': rouge_1_f / n,\n",
    "            'rouge-1_p': rouge_1_p / n,\n",
    "            'rouge-1_r': rouge_1_r / n,\n",
    "            'rouge-L_f1': rouge_L_f / n,\n",
    "            'rouge-L_p': rouge_L_p / n,\n",
    "            'rouge-L_r': rouge_L_r / n,\n",
    "            'bert_p': bert_P / n,\n",
    "            'bert_r': bert_R / n,\n",
    "            'bert_f1': bert_F1 / n\n",
    "        })\n",
    "\n",
    "    return results_summary\n",
    "\n",
    "# Perform evaluation\n",
    "results = evaluation(merged_df, scorer)\n",
    "\n",
    "# Create a DataFrame from the results summary\n",
    "results_summary_df = pd.DataFrame(results)\n",
    "\n",
    "# Save the results to a new CSV file\n",
    "results_summary_df.to_csv('Billboard_Description_Evaluation_Results_Summary.csv', index=False)\n",
    "\n",
    "# Print the results summary DataFrame to verify\n",
    "print(results_summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726639ee-9cb4-48fa-8f50-d0c1b8034004",
   "metadata": {},
   "source": [
    "## Monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9868b67c-7aa5-4849-80f0-28396b13c482",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Function to prepare the zero-shot payload\n",
    "def prepare_zero_shot_payload(lyrics):  \n",
    "    prompt = (\n",
    "        f\"Say nothing but the Description as Description: {{the output}}\\n\\n\"\n",
    "        f\"Output example: Description: The song explores themes of love and heartbreak.\\n\\n\"\n",
    "        f\"Lyrics: '{lyrics}'\\n\\n\"\n",
    "        f\"Description:\"\n",
    "    )\n",
    "    \n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    \n",
    "    payload = {\n",
    "        \"model\": \"gpt-4o\",\n",
    "        \"messages\": messages,\n",
    "        \"max_tokens\": 300,\n",
    "        \"temperature\": 0\n",
    "    }\n",
    "    \n",
    "    return payload\n",
    "\n",
    "# Function to prepare the chain-of-thought prompt payload\n",
    "def prepare_cot_payload(lyrics):\n",
    "    prompt = (\n",
    "        f\"Based on the lyrics provided, write a brief description of the song.\\n\\n\"\n",
    "        f\"Include the possible song title and artist name in the description.\\n\\n\"\n",
    "        f\"Say nothing but the Description as Description: {{the output}}\\n\\n\"\n",
    "        f\"Output example: Description: Honeymoon Avenue by Ariana Grande is about knowing you are at the end of a relationship and wishing it could not be the end and go back to the beginning and start over. \\n\\n\"\n",
    "        f\"Lyrics: '{lyrics}'\\n\\n\"\n",
    "        f\"Description:\"\n",
    "    )\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    \n",
    "    payload = {\n",
    "        \"model\": \"gpt-4o\",\n",
    "        \"messages\": messages,\n",
    "        \"max_tokens\": 300,\n",
    "        \"temperature\": 0\n",
    "    }\n",
    "    \n",
    "    return payload\n",
    "\n",
    "\n",
    "# Function to prepare the chain-of-thought few-shot prompt payload\n",
    "def prepare_cot_few_shot_payload(lyrics):\n",
    "    \n",
    "    example_lyrics = (\n",
    "        \"I'd like to say we gave it a try\\n\"\n",
    "        \"I'd like to blame it all on life\\n\"\n",
    "        \"Maybe we just weren't right\\n\"\n",
    "        \"But that's a lie, that's a lie\\n\\n\"\n",
    "\n",
    "        \"And we can deny it as much as we want\\n\"\n",
    "        \"But in time, our feelings will show\\n\"\n",
    "        \"'Cause sooner or later, we'll wonder why we gave up\\n\"\n",
    "        \"The truth is everyone knows, oh\\n\\n\"\n",
    "\n",
    "        \"Almost, almost is never enough\\n\"\n",
    "        \"So close to being in love\\n\"\n",
    "        \"If I would have known that you wanted me the way I wanted you\\n\"\n",
    "        \"Then maybe we wouldn't be two worlds apart (Ah)\\n\"\n",
    "        \"But right here in each other's arms\\n\"\n",
    "        \"And we almost, we almost knew what love was\\n\"\n",
    "        \"But almost is never enough (Ah)\\n\\n\"\n",
    "\n",
    "        \"If I could change the world overnight (Ah)\\n\"\n",
    "        \"There'd be no such thing as goodbye (Ah)\\n\"\n",
    "        \"You'd be standing right where you were (Ah)\\n\"\n",
    "        \"And we'd get the chance we deserve, oh (Ah)\\n\"\n",
    "        \"See upcoming pop shows\\n\"\n",
    "        \"Get tickets for your favorite artists\\n\\n\"\n",
    "    )\n",
    "\n",
    "    example_description = (\n",
    "        \"On the collaborative track “Almost Is Never Enough,” Ariana Grande & Nathan Sykes play a couple who had a relationship that hadn’t gone right. \"\n",
    "        \"Ariana would like to say things were going well but she knows that’s a lie and like the title states, almost is never enough to make the relationship work; you need to put full effort in. \"\n",
    "        \"Both of them state that they didn’t feel the relationship while in it, but the mood of the song and lyrics suggest that they both want to either reconnect or they simply just miss better times.\\n\\n\"\n",
    "        \"At the time of the song’s release, Nathan and Ariana were dating. Unfortunately, their relationship ended a few months later.\"\n",
    "    )\n",
    "    \n",
    "\n",
    "    prompt = (\n",
    "        f\"Example:\\n\\n\"\n",
    "        f\"Lyrics: '{example_lyrics}'\\n\\n\"\n",
    "        f\"Genre: {example_description}\\n\\n\"\n",
    "\n",
    "        f\"Based on the provided lyrics, write a brief description of the song.\\n\\n\"\n",
    "        f\"Include the possible song title and artist name in the description.\\n\\n\"\n",
    "        f\"Say nothing but the Description as Description: {{the output}}\\n\\n\"\n",
    "        f\"Output example: Description: Honeymoon Avenue by Ariana Grande is about knowing you are at the end of a relationship and wishing it could not be the end and go back to the beginning and start over. \\n\\n\"\n",
    "        f\"Lyrics: '{lyrics}'\\n\\n\"\n",
    "        f\"Description:\"\n",
    "    )\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    \n",
    "    payload = {\n",
    "        \"model\": \"gpt-4o\",\n",
    "        \"messages\": messages,\n",
    "        \"max_tokens\": 300,\n",
    "        \"temperature\": 0\n",
    "    }\n",
    "    \n",
    "    return payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0fb0da-4d0d-49de-bdd1-8ef6c0a8093b",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = # Enter your API code\n",
    "\n",
    "def make_request(payload, api_key):\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {api_key}\"\n",
    "    }\n",
    "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "    response_data = response.json()\n",
    "    return response_data\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('Billboard_weekly_filtered.csv')\n",
    "\n",
    "# Prepare the results dataframe\n",
    "results = {\n",
    "    'Title': [],\n",
    "    'Artist': [],\n",
    "    'zero_shot_Description': [],\n",
    "    'cot_Description': [],\n",
    "    'cot_few_shot_Description': []\n",
    "}\n",
    "\n",
    "result_keys = ['Title', 'Artist','zero_shot_Description','cot_Description', 'cot_few_shot_Description']\n",
    "\n",
    "# Iterate over each row in the dataframe\n",
    "count = 0\n",
    "for index, row in df.iterrows():\n",
    "    count += 1\n",
    "    if count % 100 == 0:\n",
    "        url = f'2024 Lyrics, Genre, Description Billboard Results {count}_prompt(13).csv'     ############## 여기 변경 필요\n",
    "        results_df = pd.DataFrame(results)\n",
    "        results_df.to_csv(url, index=False)\n",
    "        print(f\"Results saved to '{url}'\")\n",
    "        for keys in result_keys:\n",
    "            results[keys].clear()\n",
    "    \n",
    "    title = row['Title']\n",
    "    artist = row['Artist']\n",
    "    lyrics = row['lyrics']\n",
    "\n",
    "    # Zero-shot\n",
    "    payload = prepare_zero_shot_payload(lyrics)\n",
    "    response = make_request(payload, api_key)\n",
    "    zero_shot_response = response['choices'][0]['message']['content'].strip()\n",
    "    \n",
    "    # Extract genre and description\n",
    "    zero_shot_description = zero_shot_response.split(\"Description:\")[1].strip()\n",
    "    \n",
    "    # Chain-of-thought\n",
    "    payload = prepare_cot_payload(lyrics)\n",
    "    response = make_request(payload, api_key)\n",
    "    cot_response = response['choices'][0]['message']['content'].strip()\n",
    "    \n",
    "    # Extract genre and description\n",
    "    cot_description = cot_response.split(\"Description:\")[1].strip()\n",
    "    \n",
    "    # Chain-of-thought few-shot\n",
    "    payload = prepare_cot_few_shot_payload(lyrics)\n",
    "    response = make_request(payload, api_key)\n",
    "    cot_few_shot_response = response['choices'][0]['message']['content'].strip()\n",
    "    \n",
    "    # Extract genre and description\n",
    "    cot_few_shot_description = cot_few_shot_response.split(\"Description:\")[1].strip()\n",
    "\n",
    "    # Save the results\n",
    "    results['Title'].append(title)\n",
    "    results['Artist'].append(artist)\n",
    "    results['zero_shot_Description'].append(zero_shot_description)\n",
    "    results['cot_Description'].append(cot_description)\n",
    "    results['cot_few_shot_Description'].append(cot_few_shot_description)\n",
    "\n",
    "# Convert the results to a dataframe\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Save the results to a new CSV file\n",
    "results_df.to_csv('2024 Lyrics, Genre, Description Billboard Results 175_prompt(13).csv', index=False)\n",
    "\n",
    "print(\"Results saved to '2024 Lyrics, Genre, Description Billboard Results.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86648b5d-2779-4214-8394-7dc00b7b73cc",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922f9717-ae09-4e92-9a53-480955d67697",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from rouge_score import rouge_scorer\n",
    "from bert_score import BERTScorer\n",
    "\n",
    "# Suppress specific warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"huggingface_hub.file_download\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"transformers.modeling_utils\")\n",
    "\n",
    "def evaluate_using_rouge(reference, hypothesis):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
    "    scores = scorer.score(reference, hypothesis)\n",
    "    avg_scores = {\n",
    "        'rouge-1': scores['rouge1'],\n",
    "        'rouge-l': scores['rougeL']\n",
    "    }\n",
    "    return avg_scores\n",
    "\n",
    "def evaluate_using_bert_score(text, predicted_text, scorer):\n",
    "    P, R, F1 = scorer.score([text], [predicted_text])\n",
    "    return P.mean().item(), R.mean().item(), F1.mean().item()  # Calculate mean scores\n",
    "\n",
    "# Initializing BERT scorer\n",
    "scorer = BERTScorer(lang=\"en\", rescale_with_baseline=True)\n",
    "\n",
    "# Load the ground truth descriptions\n",
    "ground_truth_df = pd.read_csv('Billboard_weekly_filtered.csv')\n",
    "\n",
    "# Initialize variables to accumulate the scores for each description type\n",
    "file_scores = []\n",
    "\n",
    "# Use glob to find and sort all the relevant CSV files\n",
    "result_files = glob.glob('2024 Lyrics, Genre, Description Billboard Results 100_prompt(13).csv')\n",
    "result_files += glob.glob('2024 Lyrics, Genre, Description Billboard Results 175_prompt(13).csv')\n",
    "\n",
    "if not result_files:\n",
    "    print(\"No result files found. Please check the file pattern and ensure files exist.\")\n",
    "else:\n",
    "    print(f\"Found {len(result_files)} result files.\")\n",
    "\n",
    "# Loop through the sorted CSV files\n",
    "for csv_file in result_files:\n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    # Extract the file count from the filename\n",
    "    file_count = os.path.basename(csv_file).split(' ')[-1].split('.')[0]\n",
    "\n",
    "    # Merge the dataframes on Title and Artist\n",
    "    merged_df = df.merge(ground_truth_df, on=['Title', 'Artist'], how='inner')\n",
    "    \n",
    "    if merged_df.empty:\n",
    "        print(f\"No matching records found for {csv_file}. Skipping.\")\n",
    "        continue\n",
    "    \n",
    "    n = len(merged_df)\n",
    "    total_scores = {\n",
    "        'zero_shot': {'rouge1_f': 0, 'rouge1_r': 0, 'rouge1_p': 0, 'rougeL_f': 0, 'rougeL_r': 0, 'rougeL_p': 0, 'bert_p': 0, 'bert_r': 0, 'bert_f1': 0},\n",
    "        'cot': {'rouge1_f': 0, 'rouge1_r': 0, 'rouge1_p': 0, 'rougeL_f': 0, 'rougeL_r': 0, 'rougeL_p': 0, 'bert_p': 0, 'bert_r': 0, 'bert_f1': 0},\n",
    "        'cot_few_shot': {'rouge1_f': 0, 'rouge1_r': 0, 'rouge1_p': 0, 'rougeL_f': 0, 'rougeL_r': 0, 'rougeL_p': 0, 'bert_p': 0, 'bert_r': 0, 'bert_f1': 0}\n",
    "    }\n",
    "\n",
    "    # Iterate through the merged dataframe and calculate scores for each description type\n",
    "    for _, row in merged_df.iterrows():\n",
    "        reference = row['description']\n",
    "        \n",
    "        for desc_type in ['zero_shot', 'cot', 'cot_few_shot']:\n",
    "            hypothesis = row[f'{desc_type}_Description']\n",
    "            \n",
    "            # Evaluate using ROUGE\n",
    "            rouge_scores = evaluate_using_rouge(reference, hypothesis)\n",
    "            total_scores[desc_type]['rouge1_f'] += rouge_scores['rouge-1'].fmeasure\n",
    "            total_scores[desc_type]['rouge1_r'] += rouge_scores['rouge-1'].recall\n",
    "            total_scores[desc_type]['rouge1_p'] += rouge_scores['rouge-1'].precision\n",
    "            total_scores[desc_type]['rougeL_f'] += rouge_scores['rouge-l'].fmeasure\n",
    "            total_scores[desc_type]['rougeL_r'] += rouge_scores['rouge-l'].recall\n",
    "            total_scores[desc_type]['rougeL_p'] += rouge_scores['rouge-l'].precision\n",
    "            \n",
    "            # Evaluate using BERTScore\n",
    "            P, R, F1 = evaluate_using_bert_score(reference, hypothesis, scorer)\n",
    "            total_scores[desc_type]['bert_p'] += P\n",
    "            total_scores[desc_type]['bert_r'] += R\n",
    "            total_scores[desc_type]['bert_f1'] += F1\n",
    "\n",
    "    # Calculate the average scores for this file\n",
    "    if n > 0:\n",
    "        avg_scores = {\n",
    "            desc_type: {\n",
    "                'avg_rouge1_f': round(total_scores[desc_type]['rouge1_f'] / n, 4),\n",
    "                'avg_rouge1_r': round(total_scores[desc_type]['rouge1_r'] / n, 4),\n",
    "                'avg_rouge1_p': round(total_scores[desc_type]['rouge1_p'] / n, 4),\n",
    "                'avg_rougeL_f': round(total_scores[desc_type]['rougeL_f'] / n, 4),\n",
    "                'avg_rougeL_r': round(total_scores[desc_type]['rougeL_r'] / n, 4),\n",
    "                'avg_rougeL_p': round(total_scores[desc_type]['rougeL_p'] / n, 4),\n",
    "                'avg_bert_p': round(total_scores[desc_type]['bert_p'] / n, 4),\n",
    "                'avg_bert_r': round(total_scores[desc_type]['bert_r'] / n, 4),\n",
    "                'avg_bert_f1': round(total_scores[desc_type]['bert_f1'] / n, 4)\n",
    "            }\n",
    "            for desc_type in ['zero_shot', 'cot', 'cot_few_shot']\n",
    "        }\n",
    "        file_scores.append((file_count, os.path.basename(csv_file), avg_scores))\n",
    "\n",
    "# Prepare the summary dataframe\n",
    "summary_data = {\n",
    "    'File Count': [file_score[0] for file_score in file_scores],\n",
    "    'File': [file_score[1] for file_score in file_scores]\n",
    "}\n",
    "\n",
    "# Calculate the overall average scores\n",
    "if file_scores:\n",
    "    overall_avg_scores = {\n",
    "        desc_type: {\n",
    "            'avg_rouge1_f': round(sum(file_score[2][desc_type]['avg_rouge1_f'] for file_score in file_scores) / len(file_scores), 4),\n",
    "            'avg_rouge1_r': round(sum(file_score[2][desc_type]['avg_rouge1_r'] for file_score in file_scores) / len(file_scores), 4),\n",
    "            'avg_rouge1_p': round(sum(file_score[2][desc_type]['avg_rouge1_p'] for file_score in file_scores) / len(file_scores), 4),\n",
    "            'avg_rougeL_f': round(sum(file_score[2][desc_type]['avg_rougeL_f'] for file_score in file_scores) / len(file_scores), 4),\n",
    "            'avg_rougeL_r': round(sum(file_score[2][desc_type]['avg_rougeL_r'] for file_score in file_scores) / len(file_scores), 4),\n",
    "            'avg_rougeL_p': round(sum(file_score[2][desc_type]['avg_rougeL_p'] for file_score in file_scores) / len(file_scores), 4),\n",
    "            'avg_bert_p': round(sum(file_score[2][desc_type]['avg_bert_p'] for file_score in file_scores) / len(file_scores), 4),\n",
    "            'avg_bert_r': round(sum(file_score[2][desc_type]['avg_bert_r'] for file_score in file_scores) / len(file_scores), 4),\n",
    "            'avg_bert_f1': round(sum(file_score[2][desc_type]['avg_bert_f1'] for file_score in file_scores) / len(file_scores), 4)\n",
    "        }\n",
    "        for desc_type in ['zero_shot', 'cot', 'cot_few_shot']\n",
    "    }\n",
    "\n",
    "    for desc_type in ['zero_shot', 'cot', 'cot_few_shot']:\n",
    "        summary_data[f'{desc_type.capitalize()} ROUGE-1 F1'] = [\n",
    "            round(file_score[2][desc_type]['avg_rouge1_f'], 4) for file_score in file_scores\n",
    "        ]\n",
    "        \n",
    "        summary_data[f'{desc_type.capitalize()} ROUGE-1 Recall'] = [\n",
    "            round(file_score[2][desc_type]['avg_rouge1_r'], 4) for file_score in file_scores\n",
    "        ]\n",
    "        \n",
    "        summary_data[f'{desc_type.capitalize()} ROUGE-1 Precision'] = [\n",
    "            round(file_score[2][desc_type]['avg_rouge1_p'], 4) for file_score in file_scores\n",
    "        ]\n",
    "        \n",
    "        summary_data[f'{desc_type.capitalize()} ROUGE-L F1'] = [\n",
    "            round(file_score[2][desc_type]['avg_rougeL_f'], 4) for file_score in file_scores\n",
    "        ]\n",
    "        \n",
    "        summary_data[f'{desc_type.capitalize()} ROUGE-L Recall'] = [\n",
    "            round(file_score[2][desc_type]['avg_rougeL_r'], 4) for file_score in file_scores\n",
    "        ]\n",
    "        \n",
    "        summary_data[f'{desc_type.capitalize()} ROUGE-L Precision'] = [\n",
    "            round(file_score[2][desc_type]['avg_rougeL_p'], 4) for file_score in file_scores\n",
    "        ]\n",
    "        \n",
    "        summary_data[f'{desc_type.capitalize()} BERTScore Precision'] = [\n",
    "            round(file_score[2][desc_type]['avg_bert_p'], 4) for file_score in file_scores\n",
    "        ]\n",
    "        \n",
    "        summary_data[f'{desc_type.capitalize()} BERTScore Recall'] = [\n",
    "            round(file_score[2][desc_type]['avg_bert_r'], 4) for file_score in file_scores\n",
    "        ]\n",
    "        \n",
    "        summary_data[f'{desc_type.capitalize()} BERTScore F1'] = [\n",
    "            round(file_score[2][desc_type]['avg_bert_f1'], 4) for file_score in file_scores\n",
    "        ]\n",
    "\n",
    "    # Add the \"Total\" row for each metric\n",
    "    summary_data['File Count'].append('Total')\n",
    "    summary_data['File'].append('Total')\n",
    "    for desc_type in ['zero_shot', 'cot', 'cot_few_shot']:\n",
    "        summary_data[f'{desc_type.capitalize()} ROUGE-1 F1'].append(round(overall_avg_scores[desc_type]['avg_rouge1_f'], 4))\n",
    "        summary_data[f'{desc_type.capitalize()} ROUGE-1 Recall'].append(round(overall_avg_scores[desc_type]['avg_rouge1_r'], 4))\n",
    "        summary_data[f'{desc_type.capitalize()} ROUGE-1 Precision'].append(round(overall_avg_scores[desc_type]['avg_rouge1_p'], 4))\n",
    "        summary_data[f'{desc_type.capitalize()} ROUGE-L F1'].append(round(overall_avg_scores[desc_type]['avg_rougeL_f'], 4))\n",
    "        summary_data[f'{desc_type.capitalize()} ROUGE-L Recall'].append(round(overall_avg_scores[desc_type]['avg_rougeL_r'], 4))\n",
    "        summary_data[f'{desc_type.capitalize()} ROUGE-L Precision'].append(round(overall_avg_scores[desc_type]['avg_rougeL_p'], 4))\n",
    "        summary_data[f'{desc_type.capitalize()} BERTScore Precision'].append(round(overall_avg_scores[desc_type]['avg_bert_p'], 4))\n",
    "        summary_data[f'{desc_type.capitalize()} BERTScore Recall'].append(round(overall_avg_scores[desc_type]['avg_bert_r'], 4))\n",
    "        summary_data[f'{desc_type.capitalize()} BERTScore F1'].append(round(overall_avg_scores[desc_type]['avg_bert_f1'], 4))\n",
    "\n",
    "    # Create the summary dataframe\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "    summary_df.to_csv('Billboard_Description_GPT_4o_experiment_results_2024_prompt(13).csv', index=False)\n",
    "\n",
    "    print(\"Summary of results saved to 'Billboard_Description_GPT_4o_experiment_results_2024_prompt(13).csv'\")\n",
    "\n",
    "else:\n",
    "    print(\"No data found in the specified files.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
