{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7427c3aa-08f6-4686-a174-71551a07d5af",
   "metadata": {},
   "source": [
    "# Yearly - Title, Artist, Lyrics, Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906aacc4-55b5-4b10-81fe-159830db6ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import re\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Initialize Selenium WebDriver\n",
    "def init_driver():\n",
    "    service = Service(ChromeDriverManager().install())\n",
    "    return webdriver.Chrome(service=service)\n",
    "\n",
    "def melon_collector(url, year):\n",
    "    driver = init_driver()\n",
    "    time.sleep(5)\n",
    "    driver.get(url)\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    # Extract song information\n",
    "    song_info = soup.find_all('div', attrs={'class': 'ellipsis rank01'})\n",
    "    singer_info = soup.find_all('div', attrs={'class': 'ellipsis rank02'})\n",
    "    \n",
    "    # Extract IDs for the top 100 songs\n",
    "    songid = []\n",
    "    for i in range(100):\n",
    "        try:\n",
    "            songid.append(re.sub(r'[^0-9]', '', song_info[i].find(\"a\")[\"href\"][43:]))\n",
    "        except:\n",
    "            songid.append('')\n",
    "            continue\n",
    "        \n",
    "    songs = []\n",
    "    for i in songid:\n",
    "        try:\n",
    "            driver.get(\"https://www.melon.com/song/detail.htm?songId=\" + i)\n",
    "            time.sleep(2)\n",
    "            title = song_info[songid.index(i)].text.strip()\n",
    "            singer = singer_info[songid.index(i)].text.strip()\n",
    "            singer = singer[:len(singer) // 2]\n",
    "            lyric = driver.find_element(By.CLASS_NAME, \"lyric\").text.strip()\n",
    "            meta_info = driver.find_element(By.CSS_SELECTOR, \".list\").text.split('\\n')\n",
    "            like_count = driver.find_element(By.ID, \"d_like_count\").text\n",
    "\n",
    "            songs.append({\n",
    "                \"Title\": title, \n",
    "                \"Artist\": singer, \n",
    "                \"Lyrics\": lyric,\n",
    "                \"Album Name\": meta_info[1],\n",
    "                \"Release Date\": meta_info[3],\n",
    "                \"Genre\": meta_info[5], \n",
    "                \"Likes\": like_count\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching data for song ID {i}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    df = pd.DataFrame(songs)\n",
    "    output_csv_path = f'melon_{year}.csv'\n",
    "    df.to_csv(output_csv_path, index=False)\n",
    "    driver.quit()\n",
    "\n",
    "# Generate URLs and collect data for each year\n",
    "def collect_year_end_charts():\n",
    "    base_url = 'https://www.melon.com/chart/age/index.htm?chartType=YE&chartGenre=KPOP&chartDate='\n",
    "    current_year = datetime.now().year\n",
    "    start_year = 2019\n",
    "\n",
    "    for year in range(start_year, current_year + 1):\n",
    "        if year < current_year:\n",
    "            url = base_url + str(year)\n",
    "        else:  # For the current year, use the current month's or week's chart\n",
    "            url = 'https://www.melon.com/chart/index.htm'\n",
    "        \n",
    "        melon_collector(url, year)\n",
    "        print(f'Year {year} data collection complete.')\n",
    "\n",
    "# Execute the collection function\n",
    "collect_year_end_charts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6bf42d-b0d1-4bca-be18-acd6a1c9b181",
   "metadata": {},
   "source": [
    "# Monthly - Title, Artist, Lyrics, Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17197f92-dcd3-49fd-b776-8b2420b9aed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import re\n",
    "import pandas as pd\n",
    "from itertools import repeat\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver as wd\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "def init_driver():\n",
    "    options = Options()\n",
    "    options.add_argument('--headless')\n",
    "    options.add_argument('--no-sandbox')\n",
    "    options.add_argument('--disable-dev-shm-usage')\n",
    "    driver = wd.Chrome(service=ChromeService(ChromeDriverManager().install()), options=options)\n",
    "    return driver\n",
    "\n",
    "def get_melon_chart_data():\n",
    "    period = 1\n",
    "    month = 3\n",
    "    result_df = pd.DataFrame()\n",
    "\n",
    "    while period < 4:\n",
    "        try:\n",
    "            # Initialize the driver\n",
    "            driver = init_driver()\n",
    "            driver.maximize_window()  # Maximize the browser window\n",
    "\n",
    "            # Access the Melon chart page\n",
    "            url = 'https://www.melon.com/chart/index.htm'\n",
    "            driver.get(url)\n",
    "            time.sleep(2)\n",
    "\n",
    "            # Click the chart finder\n",
    "            driver.find_element(By.XPATH, '//*[@id=\"gnb_menu\"]/ul[1]/li[1]/div/div/button/span').click()\n",
    "            time.sleep(2)\n",
    "\n",
    "            # Click the monthly chart option\n",
    "            driver.find_element(By.XPATH, '//*[@id=\"d_chart_search\"]/div/h4[2]/a').click()\n",
    "            time.sleep(2)\n",
    "\n",
    "            # Select the period\n",
    "            driver.find_element(By.XPATH, f'//*[@id=\"d_chart_search\"]/div/div/div[1]/div[1]/ul/li[{period}]/span/label').click()\n",
    "            time.sleep(2)\n",
    "\n",
    "            # Select the year\n",
    "            driver.find_element(By.XPATH, '//*[@id=\"d_chart_search\"]/div/div/div[2]/div[1]/ul/li[2]/span/label').click()\n",
    "            time.sleep(2)\n",
    "\n",
    "            # Select the month\n",
    "            driver.find_element(By.XPATH, f'//*[@id=\"d_chart_search\"]/div/div/div[3]/div[1]/ul/li[{month}]/span/label').click()\n",
    "            time.sleep(2)\n",
    "\n",
    "            # Select the genre\n",
    "            driver.find_element(By.XPATH, '//*[@id=\"d_chart_search\"]/div/div/div[5]/div[1]/ul/li[1]/span/label').click()\n",
    "            time.sleep(2)\n",
    "\n",
    "            # Click the search button\n",
    "            driver.find_element(By.XPATH, '//*[@id=\"d_srch_form\"]/div[2]/button/span/span').click()\n",
    "            time.sleep(2)\n",
    "\n",
    "            # Get the HTML content and parse it with BeautifulSoup\n",
    "            html = driver.page_source\n",
    "            soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "            # Extract song IDs\n",
    "            song_info = soup.find_all('div', attrs={'class': 'ellipsis rank01'})\n",
    "            singer_info = soup.find_all('div', attrs={'class': 'ellipsis rank02'})\n",
    "            songid = [re.sub(r'[^0-9]', '', info.find(\"a\")[\"href\"][43:]) for info in song_info]\n",
    "\n",
    "            # Collect detailed song information\n",
    "            songs = []\n",
    "            for i in songid:\n",
    "                try:\n",
    "                    driver.get(f\"https://www.melon.com/song/detail.htm?songId={i}\")\n",
    "                    WebDriverWait(driver, 20).until(\n",
    "                        EC.presence_of_element_located((By.CLASS_NAME, 'lyric'))\n",
    "                    )\n",
    "                    title = song_info[songid.index(i)].text.strip()\n",
    "                    singer = singer_info[songid.index(i)].text.strip()\n",
    "                    singer = singer[:len(singer) // 2]\n",
    "                    lyric = driver.find_element(By.CLASS_NAME, \"lyric\").text.strip()\n",
    "                    meta_info = driver.find_element(By.CSS_SELECTOR, \".list\").text.split('\\n')\n",
    "                    like_count = driver.find_element(By.ID, \"d_like_count\").text\n",
    "\n",
    "                    songs.append({\n",
    "                        \"Title\": title, \n",
    "                        \"Artist\": singer, \n",
    "                        \"Lyrics\": lyric,\n",
    "                        \"Genre\": meta_info[5]\n",
    "                    })\n",
    "                except Exception as e:\n",
    "                    print(f\"Error fetching data for song ID {i}: {e}\")\n",
    "                    continue\n",
    "\n",
    "            # Convert to DataFrame\n",
    "            df = pd.DataFrame(songs)\n",
    "            result_df = pd.concat([result_df, df], ignore_index=True)\n",
    "\n",
    "            # Increment the period for the next iteration\n",
    "            period += 2\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error at period {period}: {e}\")\n",
    "            break\n",
    "\n",
    "        finally:\n",
    "            driver.quit()\n",
    "\n",
    "    return result_df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Get the Melon chart data\n",
    "    result_df = get_melon_chart_data()\n",
    "\n",
    "    # Save the DataFrame to a CSV file\n",
    "    result_df.to_csv('melon_chart_Mar_2024.csv', index=False, encoding='utf-8')\n",
    "    print(\"Data collection complete. CSV file saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9509e8a0-520d-4852-8200-973735720042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erasing Duplicates & Combining to one file\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# List of CSV files to be combined\n",
    "csv_files = [\n",
    "    'melon_chart_Jan_2024.csv',\n",
    "    'melon_chart_Feb_2024.csv',\n",
    "    'melon_chart_Mar_2024.csv',\n",
    "    'melon_chart_april_2024.csv'\n",
    "]\n",
    "\n",
    "# Read and concatenate the CSV files into a single DataFrame\n",
    "combined_df = pd.concat([pd.read_csv(file) for file in csv_files])\n",
    "\n",
    "# Drop the 'Likes' column\n",
    "if 'Likes' in combined_df.columns:\n",
    "    combined_df.drop(columns=['Likes'], inplace=True)\n",
    "\n",
    "# Remove duplicates, keeping only the first occurrence\n",
    "combined_df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Save the combined DataFrame to a new CSV file\n",
    "combined_df.to_csv('melon_chart_combined_2024.csv', index=False, encoding='utf-8')\n",
    "\n",
    "print(\"Data combined and saved to 'melon_chart_combined_2024.csv'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
